---
title: "AnimalFecalSamples16s"
author: "Rajani"
date: "November 29, 2018"
output: pdf_document
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:
## The DADA2 Workflow

1. Preprocessing
2. Filter and Trim
3. Learn Error Rates
4. Denoise/Sample Inference
5. Merge (if paired-end)
6. Remove Chimeras
7. Assign Taxonomy

Throughout: Sanity checks!

## Preprocessing, Filtering and Trimming
The data includes 16s animal fecal samples from Alpaca 1, Avian 1, Canine 105, Equine 70, Feline 15, Ovine 5. These samples were collected from Clinical microbiology laboratory at NCSU-CVM between the period of December 2016 to October 2017. The sequencing of this dataset was carried out on the Illumina MiSeq platform at the Microbial Systems Molecular Biology Laboratory (MSMBL), University of Michigan by targeting the V4 region. 200 samples were actually send for sequencing. Naga from Ben's lab already ran these samples in two sets. The first set had 21 samples and the remaining was ran in the second set. I removed few samples that were either errors/ lack of metadata/less read as per naga.
## Preprocessing

**This workflow assumes that your sequencing data meets certain criteria:**

- Samples have been demultiplexed, i.e. split into individual per-sample fastq files.
- Non-biological nucleotides have been removed, e.g. primers, adapters, linkers, etc.
- If paired-end sequencing data, the forward and reverse fastq files contain reads in matched order.
(This was already performed by Naga. I did not re do this step)
See [the DADA2 FAQ](https://benjjneb.github.io/dada2/faq.html) for tips to deal with non-demultiplexed files, primer removal
## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.
## Load package and set path

Load the `dada2` package. If you don't already it, see the [dada2 installation instructions](dada-installation.html):


```{r libraries, message=FALSE, warning=FALSE}
library(dada2); packageVersion("dada2")
```

Set the path to the fastq files:
```{r path}
path<-"C:/Users/rthanis/Desktop/16SsequencingForMS"
list.files(path)
```
## Forward, Reverse, Sample Names

Get matched lists of the forward and reverse fastq.gz files:
```{r filenames}
# Forward and reverse fastq filenames have format: SAMPLENAME_R1.fastq.gz and SAMPLENAME_R2.fastq.gz
fnFs <- sort(list.files(path, pattern="_R1_001.fastq.gz", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_R2_001.fastq.gz", full.names = TRUE))
fnFs[[1]]; fnRs[[1]]
```
Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq.gz
```{r sample.names}
sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1)
sample.names
```

```{r Quality Profile,warning=FALSE,message=FALSE}
plotQualityProfile(fnFs[1:2])
plotQualityProfile(fnRs[1:2])
```

```{r filt-names}
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
```
The critical parameters I chose are the truncation lengths of **230** (forward) and **160** (reverse). *based on my quality profile plot*
```{r filter, message=FALSE, warning=FALSE}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, 
                     truncLen=c(230,160), maxEE=c(2,2), # maxEE=2 is the default
                     compress=TRUE, multithread=TRUE) # Set multithread=TRUE to use all cores
```

```{r filter-stats}
head(out)
```
## Learn error rates and Denoise

## Learn the Error Rates
```{r learn-errors}
errF <- learnErrors(filtFs, multithread=TRUE) # Set multithread=TRUE to use all cores
saveRDS(errF,"C:/Users/rthanis/Desktop/16SsequencingForMS/errF.rds")
errR <- learnErrors(filtRs, multithread=TRUE)
saveRDS(errR,"C:/Users/rthanis/Desktop/16SsequencingForMS/errR.rds")
```
## SANITY CHECK: Error Rates
```{r plot-errors, warning=FALSE}
plotErrors(errF, nominalQ=TRUE)
```
## Dereplicate
Dereplication combines all identical sequencing reads into "unique sequences" with a corresponding "abundance" equal to the number of reads with that unique sequence.
```{r dereplicate, message=FALSE}
derepFs <- derepFastq(filtFs)
derepRs <- derepFastq(filtRs)
# Name the derep-class objects by the sample names
names(derepFs) <- sample.names
names(derepRs) <- sample.names
```
## Sample Inference
```{r dada}
dadaFs <- dada(derepFs, err=errF, multithread=TRUE) # Set multithread=TRUE to use all cores
dadaRs <- dada(derepRs, err=errR, multithread=TRUE)
saveRDS(dadaFs,"C:/Users/rthanis/Desktop/16SsequencingForMS/dadaFs.rds")
saveRDS(dadaRs,"C:/Users/rthanis/Desktop/16SsequencingForMS/dadaRs.rds")
```

```{r see-dada}
dadaFs[[1]]
```
The `getSequences` and `getUniques` functions work on just about any dada2-created object. `getUniques` returns an integer vector, named by the sequences and valued by their abundances. `getSequences` just returns the sequences.
```{r}
head(getSequences(dadaFs[[1]]))
```
##Merge paired reads
We can now merge the forward and reverse reads together to obtain the de-noised amplicon sequences
```{r merge, message=FALSE}
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose=TRUE)
saveRDS(mergers,"C:/Users/rthanis/Desktop/16SsequencingForMS/mergers.RDS")
```
## Construct Sequence Table (ASV Table)
After merging the reads, we can construct a sequence table containing all the ASV as a table. After construction of this table, the ASV table is also filtered for chimeric sequences. The length of the reads gives us an idea of proper merging of the obtained reads, the ratio of chimera removed vs non-chimera removed sequences shows how many sequences were chimeric in this dataset
```{r seqtab}
# mergers <- readRDS("C:/Users/rthanis/Desktop/16SsequencingForMS/mergers.RDS")
seqtab <- makeSequenceTable(mergers)
saveRDS(seqtab,"C:/Users/rthanis/Desktop/16SsequencingForMS/seqtab.rds")
```
The sequence table is a `matrix` with rows corresponding to (and named by) the samples, and columns corresponding to (and named by) the sequence variants.
```{r dim}
dim(seqtab)
```
# Inspect distribution of sequence lengths
```{r seqlens}
table(nchar(getSequences(seqtab)))
```
The lengths of the merged sequences all fall in the expected range for this amplicon.

## Remove chimeras
Chimeric sequences are identified if they can be exactly reconstructed by combining a left-segment and a right-segment from two more abundant "parent" sequences.
```{r chimeras, message=FALSE}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
saveRDS(seqtab.nochim,"C:/Users/rthanis/Desktop/16SsequencingForMS/seqtab_nochim.rds")
dim(seqtab.nochim)
sum(seqtab.nochim)/sum(seqtab)
```
##Tracking the reads through the DADA2 pipeline
Tracking the reads after applying all the steps and identifying how many reads were lost through the entire process. Applying this step allows us to know if we need to re-analyze the data if we lose too many reads.
```{r track}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
head(track)
#dadaFs <- readRDS("C:/Users/rthanis/Desktop/16SsequencingForMS/dadaFs.rds")
#dadaRs <- readRDS("C:/Users/rthanis/Desktop/16SsequencingForMS/dadaRs.rds")
```
## SANITY CHECK: Read Tracking
```{r track2}
head(track)
```
## Assign Taxonomy

The `assignTaxonomy` function takes as input a set of sequences to ba classified, and a training set of reference sequences with known taxonomy, and outputs taxonomic assignments with at least `minBoot` bootstrap confidence. 
```{r taxify}
seqtab.nochim <- readRDS("C:/Users/rthanis/Desktop/16SsequencingForMS/seqtab_nochim.rds")
taxa <- assignTaxonomy(seqtab.nochim, "C:/Users/rthanis/Desktop/16SsequencingForMS/silva_nr_v132_train_set.fa.gz",
multithread=TRUE)
saveRDS(taxa,"C:/Users/rthanis/Desktop/16SsequencingForMS/taxa.RDS")

taxa <- readRDS("C:/Users/rthanis/Desktop/16SsequencingForMS/taxa.RDS")

taxa <- addSpecies(taxa, "C:/Users/rthanis/Desktop/CS_2017/silva_species_assignment_v132.fa.gz", allowMultiple = TRUE, n=1000)
saveRDS(taxa,"C:/Users/rthanis/Desktop/16SsequencingForMS/taxa.RDS")
```

```{r}
library("phyloseq")
setwd("C:/Users/rthanis/Desktop/16SsequencingForMS")
```


```{r}
path <- "C:/Users/rthanis/Desktop/16SsequencingForMS"
# Load previous dada2 output
seqtab.nochim <- readRDS(file.path(path, "seqtab_nochim.rds"))
taxa <- readRDS(file.path(path, "taxa.RDS"))
# load sample data and turn into data frame with rows as Sample names
sam <- readxl::read_excel(file.path(path, "Metadata_12.17.18.xlsx"))
samdf <- as.data.frame(sam[, -1])
rownames(samdf) <- sam$Sample

# Make the sample names match for the ~20 early samples
library(dplyr)
sam <- sam %>%
  mutate(Seqtab_name = stringr::str_replace(ID, "_", "-"))
# alternative:
# sam$Seqtab_name <- stringr::str_replace(sam$ID, "_", "-")
new_names <- sam$Sample[match(rownames(seqtab.nochim), sam$Seqtab_name)]
# Check in the right order
rownames(seqtab.nochim) %>% head(n=20)
new_names %>% head(n=20)
# Rename
rownames(seqtab.nochim) <- new_names

# Get phyloseq versions of everything
OTU <- otu_table(seqtab.nochim, taxa_are_rows = FALSE)
SAM <- sample_data(samdf)
TAX <- tax_table(taxa)

# Combine into a phyloseq object
ps <- phyloseq(OTU, SAM, TAX)

# Add ASV sequences
seqs <- Biostrings::DNAStringSet(taxa_names(ps))
names(seqs) <- taxa_names(ps)
seqs

ps <- merge_phyloseq(ps, seqs)
ps

# Now you are free to give the ASVs/taxa simpler names and you can always fetch the full sequences
taxa_names(ps) <- paste0("SV", seq(ntaxa(ps)))

# To go back to original names:
# taxa_names(ps) <- refseq(ps)
saveRDS(ps,"C:/Users/rthanis/Desktop/16SsequencingForMS/ps.RDS")
```



```{r}
library(ggplot2)
packageVersion("ggplot2")
library(vegan)
library(permute)
library(lattice)
packageVersion("vegan")
library(MASS)
packageVersion("MASS")
```
```{r}
plot_richness(ps, x="Species", measures=c("Chao1", "Shannon", "Simpson"), color="CD")
```

```{r}
plot_richness(ps, x="Species", measures=c("Chao1", "Shannon", "Simpson", "Observed"), color="CD")
```
?Observedspecies
```{r}
plot_richness(tax_glom(ps, "Family"), x="Species", measures=c("Chao1", "Shannon", "Simpson","InvSimpson", "Observed"), color="CD")
```
```{r}
# ps<-phyloseq(otu_table(seqtab.nochim,taxa_are_rows = FALSE),sample_data(samdf),tax_table(taxa))
ord.nmds.bray <- ordinate(ps, method="NMDS", distance="bray")
plot_ordination(ps, ord.nmds.bray, color="CD", shape="Species",title="Bray NMDS")
```

```{r}
ps.prop<-transform_sample_counts(ps, function(x) 1000 * x/(sum(x)))
ords.nmds.bray<-ordinate(ps.prop,method = "NMDS",distance = "bray")
plot_ordination(ps.prop,ords.nmds.bray,color = "Species",shape = "CD") + 
  geom_point(size=2.5) + 
  scale_color_manual(values=c( "#DA8D06","#000000","#489BE5", "#F53112","#AE43A7")) +
  scale_shape_manual(values = c(19,2))
df = as(sample_data(ps.prop),"data.frame")
df_taxa<-as(otu_table(ps.prop), "matrix")
betad<-betadiver(df_taxa, "z")
mod<-with(df,betadisper(betad,Species))
TukeyHSD(mod)
  
```
        
```{r}
ords.PCoA.bray<-ordinate(ps.prop,method = "PCoA",distance = "bray")
plot_ordination(ps.prop,ords.PCoA.bray,color = "Species",shape = "CD") + 
  geom_point(size=2.5) + 
  scale_color_manual(values=c( "#DA8D06","#000000","#489BE5", "#F53112","#AE43A7")) +
  scale_shape_manual(values = c(19,2))
```

```{r}
top30 <- names(sort(taxa_sums(ps.prop), decreasing=TRUE))[1:30]
# ps.top30 <- transform_sample_counts(ps, function(OTU) OTU/sum(OTU))
ps.top30 <- prune_taxa(top30, ps.prop)
plot_bar(ps.top30, x="sample_Species", fill="Family")+facet_wrap(~CD, scales="free_x")
ggsave("C:/Users/rthanis/Desktop/ClinicalProject/ManuscriptPrep/Microbiome/RAFamily1.pdf", width = 6, height = 6, units = "in")
```



```{r}
ps.phyla <- transform_sample_counts(ps, function(OTU) OTU/sum(OTU))
plot_bar(ps.phyla, x="sample_Species", fill="Phylum")+facet_wrap(~CD, scales="free_x")
```

```{r}
Canine<-subset(samdf,samdf$Species=="Canine")
ID_Canine<-Canine$ID
length(ID_Canine)
(ps_Canine <- subset_samples(ps, Species == "Canine"))
saveRDS(ps_Canine ,"C:/Users/rthanis/Desktop/16SsequencingForMS/ps_Canine.RDS")
```

```{r}
Feline<-subset(samdf,samdf$Species=="Feline")
ID_Feline<-Feline$ID
length(ID_Feline)
ps_Feline <- subset_samples(ps, Species == "Feline")
saveRDS(ps,"C:/Users/rthanis/Desktop/16SsequencingForMS/ps_Feline.RDS")
```


```{r}
Equine<-subset(samdf,samdf$Species=="Equine")
ID_Equine<-Equine$ID
length(ID_Equine)
ps_Equine <- subset_samples(ps, Species == "Equine")
saveRDS(ps,"C:/Users/rthanis/Desktop/16SsequencingForMS/ps_Equine.RDS")
```

```{r}
ps_Canine<-prune_samples(sample_names(ps) %in% ID_Canine, ps)
ps_Canine
head(ID_Canine)
head(sample_names(ps))
```
```{r}
ps.prop_canine<-transform_sample_counts(ps_Canine,function(x) 1000 * x/(sum(x)))
ords.nmds.bray_Canine<-ordinate(ps.prop_canine,method = "NMDS",distance = "bray")
df = as(sample_data(ps.prop_canine),"data.frame")
df_taxa<-as(otu_table(ps.prop_canine), "matrix")
betad<-betadiver(df_taxa, "z")
mod<-with(df,betadisper(betad,CD))
TukeyHSD(mod)
```

```{r}
ps.prop_Equine<-transform_sample_counts(ps_Equine,function(x) 1000 * x/(sum(x)))
ords.nmds.bray_Equine<-ordinate(ps.prop_Equine,method = "NMDS",distance = "bray")
df = as(sample_data(ps.prop_Equine),"data.frame")
df_taxa<-as(otu_table(ps.prop_Equine), "matrix")
betad<-betadiver(df_taxa, "z")
mod<-with(df,betadisper(betad,CD))
TukeyHSD(mod)
```
```{r}
plot_ordination(ps.prop_canine,ords.nmds.bray,shape = "CD",color = "Species") + scale_color_manual(values="#000000") + geom_point(size=2.5) + scale_shape_manual(values = c(19,2))
```

```{r}
plot_ordination(ps.prop_Equine,ords.nmds.bray,shape = "CD",color = "Species") + scale_color_manual(values="#489BE5") + geom_point(size=2.5) + scale_shape_manual(values = c(19,2))
```

